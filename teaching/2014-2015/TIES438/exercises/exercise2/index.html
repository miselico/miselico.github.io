
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Approximating Jaccard Distance Between Documents - Michael Cochez</title>
  <meta name="author" content="">

  
  <meta name="description" content=" ">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://www.cochez.nl/teaching/2014-2015/TIES438/exercises/exercise2/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="" rel="alternate" title="Michael Cochez" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-54043599-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   class="no-sidebar"  >
  <header role="banner"><hgroup>
  <h1><a href="/">Michael Cochez</a></h1>
  
    <h2>Assistant Professor at Vrije Universiteit Amsterdam</h2>
  
</hgroup>

</header>
  <nav role="navigation"><!--
<ul class="subscription" data-subscription="rss">
  <li><a href="" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
-->
  
<ul class="main-navigation">
  <li><a href="/">Home</a></li>
  <li><a href="/research/">Research</a></li>
  <li><a href="/teaching/">Teaching</a></li>  
  <li><a href="/software/">Software</a></li>
  <li><a href="/contact/">Contact</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article role="article">
  
  <header>
    <h1 class="entry-title">Approximating Jaccard Distance Between Documents</h1>
    
  </header>
  
  <h2 id="goal">Goal</h2>
<p>In this exercises we will implement an algorithm which speeds up the measurement of the Jaccard similarity between documents.</p>

<h2 id="prerequisites">Prerequisites</h2>

<p>In principle, the content presented during the lectures suffices to implement this task.
However, it is certainly beneficial to study the corresponding text in chapter 3 of the <em>Mining of Massive Datasets</em> book.
You can also watch the videos of the coursera course related to LSH (in week 2).</p>

<h2 id="task">Task</h2>
<p>The task consists of four parts.
First, you need to devise a way to convert the documents to sets.
Then you need to be able to calculate the exact Jaccard distance between two of these sets.
Next, you will use locality-sensitive hashing to calculate an approximation of the distance.
Finally, you need to evaluate the quality of the approximation.</p>

<p>For this task, the teacher has cleaned a dataset which contains paragraphs from books from Project Gutenberg (<a href="gutenberg_paragraphs.txt.zip">download</a>).
On each line of the file, you will find the words from the paragraph, with the most common words (stopwords) removed.
Each line of the file has to be be taken as a document for this exercise,</p>

<p>This task is performed either individually or as a pair. If you want to work as a pair, take a different partner as for last task.
You are free to work using the programming language you want.</p>

<h3 id="part-i">Part I</h3>
<p>Read the dataset into memory and apply one transformation on each document. This can be done as follows:</p>

<ul>
  <li>Make a list which will contain a set for each document</li>
  <li>Make a set (<code class="highlighter-rouge">allTerms</code>) which will contain all elements of these sets</li>
  <li>Until all lines are read
    <ol>
      <li>Read a line (there is one document on each line)</li>
      <li>Apply one of the following (you can apply multiple if you want and have time left):
        <ul>
          <li>Split the line (on space) and apply stemming on each word, add all words to a set.
            <ul>
              <li>Check <a href="http://tartarus.org/martin/PorterStemmer/">Porter stemming implementations</a>  for different programming languages.</li>
            </ul>
          </li>
          <li>Split the line, add the terms to a set in such a way that duplicates are preserved.
            <ul>
              <li>If the words are <code class="highlighter-rouge">[A, A, B]</code>, create the set <code class="highlighter-rouge">{A1,A2,B1}</code></li>
              <li>Optional: you can also use techniques like TF.IDF to determine the frequency in the final set.</li>
            </ul>
          </li>
          <li>Split the line, add all 2-grams to a set.
            <ul>
              <li>If the words are <code class="highlighter-rouge">[A, B, C, D, E, F, A, B, C]</code>, then the set will be <code class="highlighter-rouge">{AB, BC, CD, DE, EF, FA}</code></li>
            </ul>
          </li>
          <li>Do not split the line. Add all 5 shingles to a set.
            <ul>
              <li>If the line is <code class="highlighter-rouge">abcd efg</code>, then the set will be <code class="highlighter-rouge">{"abcd ", "bcd e", "cd ef", "d efg" }</code></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Add the set from the previous step to the list.</li>
      <li>Add all strings from the set from step 2 to the <code class="highlighter-rouge">allTerms</code> set.</li>
    </ol>
  </li>
  <li>Convert the <code class="highlighter-rouge">allTerms</code> set to a list.</li>
</ul>

<h3 id="part-ii">Part II</h3>

<p>Implement a method or function which calculates the Jaccard distance between two sets of Strings.
To do this, you first compute the size of the union and intersection, then you apply the formula for Jaccard distance.
<!-- 1 - \frac{D1 \cap D2}{D1 \cup D2} --></p>

<p><img src="jaccard_distance.svg" alt="Jaccard distance formula" /></p>

<p>Now, you should be able to calculate the distance between two of the read documents.</p>

<h3 id="part-iii">Part III</h3>
<p>First, you need to implement a min-hash algorithm, and then use it to approximate the distance between two documents.
You could implement the somewhat optimized algorithm from the course book (section 3.3.5).</p>

<p>Second, to calculate the approximate distance, we start from what was shown in class.</p>

<!-- \Pr [\text{minhash}(D1) = \text{minhash}(D2)] = 1 - \text{jaccard-distance} (D1,D2)  -->
<p><img src="approx_deriv1.svg" alt="Probaility of equal minhash is equal to 1 minus jaccard distance" /></p>

<p>And hence
<!-- \text{jaccard-distance} (D1,D2) = 1 - \Pr [\text{minhash}(D1) = \text{minhash}(D2)] -->
<img src="approx_deriv2.svg" alt="jaccard distance is equal to 1 minus Probaility of equal minhash" /></p>

<p>When applying min-hash <code class="highlighter-rouge">n</code> times (using different permutations), we can approximate the distance by</p>

<!--  \text{jaccard-distance} (D1,D2) \approx 1 - \frac{\text{number of times the signature is equal}}{n}  --->
<p><img src="approx_deriv3.svg" alt="jaccard distance is approx equal to 1 minus number of times the signature is equal divided by n" /></p>

<p>Note that <code class="highlighter-rouge">n</code> is a parameter to your approximation. A column vector containing the min-hash evaluations for a document is its signature vector.
When these vectors are placed into a matrix, it is called the signature matrix of the documents.
Hence, to approximate the distance with <code class="highlighter-rouge">n</code> min-hash functions, you need to calculate the signature vector for both documents and determine in how many places they agree.</p>

<h3 id="part-iv">Part IV</h3>
<p>To evaluate the quality of the approximation, we will observe how much it deviates from the real value.
Concretely, we will calculate the average absolute error for 100 random distance calculations.</p>

<p>Work as follows:</p>

<ul>
  <li>For each distance calculation(100):
    <ul>
      <li>Select D1 and D2 at random from the documents</li>
      <li>Calculate the real distance between D1 and D2</li>
      <li>For <code class="highlighter-rouge">n</code> in [5, 10, 20, 40, 80]:
        <ul>
          <li>Calculate the approximate distance.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>Finally, for each <code class="highlighter-rouge">n</code>, calculate the average error as follows:
<!-- \frac{\sum\limits_{i=1}^{100} \lvert \text{jaccard-distance}(D_1,D_2) - \text{approx. distance}(D_1,D_2) \rvert}{100} --></p>

<p><img src="average_error.svg" alt="average error" /></p>

<p>Create a chart in which you plot the error in function of <code class="highlighter-rouge">n</code>.</p>

<h2 id="note">Note</h2>
<p>Normally, you would pre-calculate the signatures for all documents and not keep the documents themselves in memory (normal documents will be much longer than the paragraphs, for instance whole web pages).
After this has been done you can very fast answer queries for the distance between two documents.
In general, it is a bad idea, or even impossible, to pre-calculate all the distance between documents, since these distances need O(N^2) storage space.
For instance, for 2  million documents, and 4 bytes per distance, this would be 7451 Gb.
I we instead use signatures of length 100, using 4 bytes for the min-hash outcome, we need 0.745 Gb of space.</p>

<h2 id="hints">Hints</h2>

<ol>
  <li>Use small part of the data during development. If you notice that your implementation is slow, you can use a reduced set (min 2000) of documents for the evaluation.</li>
  <li>For the programming language, you might just want to choose the one you are most familiar with. Depending on the chosen language the teacher will be able to help more (or less) with language specific issues.</li>
  <li>Randomized algorithms are difficult to debug. Make it somehow possible by fixing the seed of the random number generator. At least each run will be the same.</li>
  <li>People using Java should check the <a href="http://code.google.com/p/guava-libraries/">Guava Libraries</a>, in particular classes for splitting strings and working with sets.</li>
  <li>The operation for permuting lists is most often called shuffle. For instance,
in Java <a href="https://docs.oracle.com/javase/7/docs/api/java/util/Collections.html#shuffle%28java.util.List,%20java.util.Random%29">Collections.shuffle(List&lt;?&gt; list, Random rnd)</a>
or in Python <a href="https://docs.python.org/2/library/random.html#random.shuffle">random.shuffle(x[, random])</a>. Not that both of these permute the list in-place (no copy is made).</li>
  <li>Most of the distances will be close to 1. More concrete, when performing a million random samples the frequency of a given distance occurring looks like this:<img src="distance_frequency.svg" alt="frequency of a given distance" /></li>
</ol>


  
    <footer>
      
      
        <div class="sharing">
  
  
  
</div>

      
    </footer>
  
</article>

</div>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2022 - Michael Cochez -
  <span class="credit">Powered by Jekyll. Derived from Octopress.</span>
</p>

</footer>
  











</body>
</html>
